"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä "–≤–æ–¥—ã" –≤ —Ç–µ–∫—Å—Ç–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å logreg_water_model.pkl –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–¥—è–Ω–∏—Å—Ç–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞
"""

import re
import joblib
import pandas as pd
import pymorphy3
from collections import Counter
from typing import Dict, Tuple, List
import nltk
from nltk.corpus import stopwords


class WaterDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä '–≤–æ–¥—ã' –≤ —Ç–µ–∫—Å—Ç–∞—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, model_path: str = "logreg_water_model.pkl"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        
        Args:
            model_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
        """
        print(f"üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WaterDetector...")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        try:
            self.model = joblib.load(model_path)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_path}")
        except FileNotFoundError:
            raise FileNotFoundError(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ {model_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        self.morph = pymorphy3.MorphAnalyzer()
        print("‚úÖ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä pymorphy3 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤
        try:
            self.ru_stopwords = set(stopwords.words("russian"))
        except LookupError:
            print("‚è≥ –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç–æ–ø-—Å–ª–æ–≤–∞...")
            nltk.download('stopwords', quiet=True)
            self.ru_stopwords = set(stopwords.words("russian"))
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.ru_stopwords)} —Ä—É—Å—Å–∫–∏—Ö —Å—Ç–æ–ø-—Å–ª–æ–≤")
        
        # –ù–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–æ–ª–∂–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–∏)
        self.feature_names = [
            "readability_index", 
            "stopword_ratio", 
            "adj_ratio", 
            "adv_ratio", 
            "repetition_ratio"
        ]
        
        print("üéâ WaterDetector –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!\n")
    
    def count_syllables(self, word: str) -> int:
        """
        –ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≥–æ–≤ –≤ —Å–ª–æ–≤–µ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ: 1 –≥–ª–∞—Å–Ω–∞—è = 1 —Å–ª–æ–≥)
        
        Args:
            word: –°–ª–æ–≤–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≥–æ–≤
        """
        vowels = '–∞–µ—ë–∏–æ—É—ã—ç—é—è–ê–ï–Å–ò–û–£–´–≠–Æ–Ø'
        count = 0
        for char in word:
            if char in vowels:
                count += 1
        return count
    
    def analyze_text_simple(self, text: str) -> Tuple[int, int, int]:
        """
        –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≥–æ–≤)
        """
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        raw_sentences = re.split(r'[.!?‚Ä¶]+', text)
        sentences = [s.strip() for s in raw_sentences if s.strip()]
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ä—É—Å—Å–∫–∏–µ —Å–ª–æ–≤–∞
        words = re.findall(r'\b[–∞-—è–ê-–Ø—ë–Å]+\b', text)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–ª–æ–≥–∏
        syllables = 0
        for word in words:
            normal_word = self.morph.parse(word)[0].normal_form
            syllables += self.count_syllables(normal_word)
        
        return len(sentences), len(words), syllables
    
    def readability_index(self, text: str) -> Tuple[float, str]:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ (—Ñ–æ—Ä–º—É–ª–∞ –§–ª–µ—à–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞)
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—á–∏—Å–ª–æ–≤–æ–π –∏–Ω–¥–µ–∫—Å, —Ç–µ–∫—Å—Ç–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è)
        """
        sentences, words, syllables = self.analyze_text_simple(text)
        
        if sentences == 0 or words == 0:
            return 0.0, "–¢–ï–ö–°–¢ –°–õ–ò–®–ö–û–ú –ö–û–†–û–¢–ö–ò–ô"
        
        # –§–æ—Ä–º—É–ª–∞ –∏–Ω–¥–µ–∫—Å–∞ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ –§–ª–µ—à–∞ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)
        index = 206.835 - 1.3 * (words / sentences) - 60.1 * (syllables / words)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        if index > 90:
            level = "–û–ß–ï–ù–¨ –í–´–°–û–ö–ò–ô"
        elif index > 80:
            level = "–í–´–°–û–ö–ò–ô"
        elif index > 70:
            level = "–í–´–®–ï –°–†–ï–î–ù–ï–ì–û"
        elif index > 60:
            level = "–°–†–ï–î–ù–ò–ô"
        elif index > 50:
            level = "–ù–ò–ñ–ï –°–†–ï–î–ù–ï–ì–û"
        elif index > 30:
            level = "–ù–ò–ó–ö–ò–ô"
        else:
            level = "–û–ß–ï–ù–¨ –ù–ò–ó–ö–ò–ô"
        
        return round(index, 2), level
    
    def stopword_ratio(self, text: str) -> float:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–æ–ª–∏ —Å—Ç–æ–ø-—Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –î–æ–ª—è —Å—Ç–æ–ø-—Å–ª–æ–≤ (–æ—Ç 0 –¥–æ 1)
        """
        words = re.findall(r'\b[–∞-—è–ê-–Ø—ë–Å]+\b', text.lower())
        
        if len(words) == 0:
            return 0.0
        
        stopword_count = sum(1 for word in words if word in self.ru_stopwords)
        ratio = stopword_count / len(words)
        
        return ratio
    
    def pos_ratios(self, text: str) -> Tuple[float, float]:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–æ–ª–µ–π –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –∏ –Ω–∞—Ä–µ—á–∏–π –≤ —Ç–µ–∫—Å—Ç–µ
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–¥–æ–ª—è –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö, –¥–æ–ª—è –Ω–∞—Ä–µ—á–∏–π)
        """
        words = re.findall(r'\b[–∞-—è–ê-–Ø—ë–Å]+\b', text)
        pos = Counter()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç—å —Ä–µ—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞
        for w in words:
            p = self.morph.parse(w)[0].tag.POS
            pos[p] += 1
        
        total = sum(pos.values())
        if total == 0:
            return 0.0, 0.0
        
        # ADJF - –ø–æ–ª–Ω–æ–µ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ, ADJS - –∫—Ä–∞—Ç–∫–æ–µ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ
        adj = pos.get("ADJF", 0) + pos.get("ADJS", 0)
        # ADVB - –Ω–∞—Ä–µ—á–∏–µ
        adv = pos.get("ADVB", 0)
        
        return adj / total, adv / total
    
    def repetition_ratio(self, text: str) -> float:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–æ–ª–∏ —Å–∞–º–æ–≥–æ —á–∞—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä—è—é—â–µ–≥–æ—Å—è —Å–ª–æ–≤–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –î–æ–ª—è —Å–∞–º–æ–≥–æ —á–∞—Å—Ç–æ–≥–æ —Å–ª–æ–≤–∞
        """
        words = re.findall(r'\b[–∞-—è–ê-–Ø—ë–Å]+\b', text.lower())
        if not words:
            return 0.0
        
        counts = Counter(words)
        max_count = max(counts.values())
        
        return max_count / len(words)
    
    def extract_features(self, text: str) -> Dict[str, float]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        # –ò–Ω–¥–µ–∫—Å —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        readability, _ = self.readability_index(text)
        
        # –î–æ–ª—è —Å—Ç–æ–ø-—Å–ª–æ–≤
        stopword_r = self.stopword_ratio(text)
        
        # –î–æ–ª–∏ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –∏ –Ω–∞—Ä–µ—á–∏–π
        adj_r, adv_r = self.pos_ratios(text)
        
        # –î–æ–ª—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
        rep_r = self.repetition_ratio(text)
        
        features = {
            "readability_index": readability,
            "stopword_ratio": stopword_r,
            "adj_ratio": adj_r,
            "adv_ratio": adv_r,
            "repetition_ratio": rep_r
        }
        
        return features
    
    def predict(self, text: str, return_proba: bool = False) -> Dict:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è '–≤–æ–¥—ã' –≤ —Ç–µ–∫—Å—Ç–µ
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            return_proba: –í–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features = self.extract_features(text)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
        X = pd.DataFrame([features])[self.feature_names]
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction = self.model.predict(X)[0]
        proba = self.model.predict_proba(X)[0]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            "text": text[:200] + "..." if len(text) > 200 else text,
            "is_water": bool(prediction),
            "water_label": "–í–û–î–ê" if prediction == 1 else "–ù–ï –í–û–î–ê",
            "confidence": float(proba[prediction]),
            "features": features
        }
        
        if return_proba:
            result["probabilities"] = {
                "not_water": float(proba[0]),
                "water": float(proba[1])
            }
        
        return result
    
    def interpret_features(self, features: Dict[str, float]) -> Dict[str, str]:
        """
        –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            features: –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è–º–∏
        """
        interpretations = {}
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        ri = features["readability_index"]
        if ri > 80:
            interpretations["readability"] = "–æ—á–µ–Ω—å –ª–µ–≥–∫–æ —á–∏—Ç–∞–µ—Ç—Å—è"
        elif ri > 60:
            interpretations["readability"] = "–Ω–æ—Ä–º–∞–ª—å–Ω–æ —á–∏—Ç–∞–µ—Ç—Å—è"
        elif ri > 40:
            interpretations["readability"] = "—Ç—è–∂–µ–ª–æ–≤–∞—Ç–æ —á–∏—Ç–∞–µ—Ç—Å—è"
        else:
            interpretations["readability"] = "—Å–ª–æ–∂–Ω–æ —á–∏—Ç–∞–µ—Ç—Å—è"
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Å—Ç–æ–ø-—Å–ª–æ–≤
        sw = features["stopword_ratio"]
        if sw < 0.25:
            interpretations["stopwords"] = "–ø–ª–æ—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç"
        elif sw < 0.35:
            interpretations["stopwords"] = "–Ω–æ—Ä–º–∞–ª—å–Ω–æ"
        else:
            interpretations["stopwords"] = "–ø–æ–¥–æ–∑—Ä–µ–Ω–∏–µ –Ω–∞ –≤–æ–¥—É (–º–Ω–æ–≥–æ —Å—Ç–æ–ø-—Å–ª–æ–≤)"
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö
        adj = features["adj_ratio"]
        if adj < 0.12:
            interpretations["adjectives"] = "—Ñ–∞–∫—Ç–æ–ª–æ–≥–∏—è"
        elif adj < 0.18:
            interpretations["adjectives"] = "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ"
        else:
            interpretations["adjectives"] = "–≤–æ–∑–º–æ–∂–Ω–∞—è –≤–æ–¥–∞ (–º–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏–π)"
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –Ω–∞—Ä–µ—á–∏–π
        adv = features["adv_ratio"]
        if adv < 0.03:
            interpretations["adverbs"] = "—Å—É—Ö–æ–π —Ç–µ–∫—Å—Ç"
        elif adv < 0.07:
            interpretations["adverbs"] = "–Ω–æ—Ä–º–∞–ª—å–Ω–æ"
        else:
            interpretations["adverbs"] = "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –≤–æ–¥–∞ (–º–Ω–æ–≥–æ –Ω–∞—Ä–µ—á–∏–π)"
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
        rep = features["repetition_ratio"]
        if rep < 0.05:
            interpretations["repetitions"] = "—Ö–æ—Ä–æ—à–æ (–º–∞–ª–æ –ø–æ–≤—Ç–æ—Ä–æ–≤)"
        elif rep < 0.1:
            interpretations["repetitions"] = "—Ç–µ—Ä–ø–∏–º–æ"
        else:
            interpretations["repetitions"] = "–≤–æ–¥–∞ (–º–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–æ–≤)"
        
        return interpretations
    
    def analyze_text(self, text: str, detailed: bool = True) -> Dict:
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            detailed: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
        """
        result = self.predict(text, return_proba=True)
        
        if detailed:
            result["interpretations"] = self.interpret_features(result["features"])
        
        return result
    
    def print_analysis(self, result: Dict):
        """
        –ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        print("\n" + "="*80)
        print("üìù –ê–ù–ê–õ–ò–ó –¢–ï–ö–°–¢–ê –ù–ê '–í–û–î–£'")
        print("="*80)
        
        print(f"\nüìÑ –¢–µ–∫—Å—Ç: {result['text']}")
        
        print(f"\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢: {result['water_label']}")
        print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']*100:.1f}%")
        
        if "probabilities" in result:
            probs = result["probabilities"]
            print(f"\nüìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:")
            print(f"   –ù–µ –≤–æ–¥–∞: {probs['not_water']*100:.1f}%")
            print(f"   –í–æ–¥–∞: {probs['water']*100:.1f}%")
        
        print(f"\nüìà –ü–†–ò–ó–ù–ê–ö–ò:")
        features = result["features"]
        print(f"   –ò–Ω–¥–µ–∫—Å —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏: {features['readability_index']:.2f}")
        print(f"   –î–æ–ª—è —Å—Ç–æ–ø-—Å–ª–æ–≤: {features['stopword_ratio']:.3f}")
        print(f"   –î–æ–ª—è –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö: {features['adj_ratio']:.3f}")
        print(f"   –î–æ–ª—è –Ω–∞—Ä–µ—á–∏–π: {features['adv_ratio']:.3f}")
        print(f"   –î–æ–ª—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π: {features['repetition_ratio']:.3f}")
        
        if "interpretations" in result:
            print(f"\nüí° –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø:")
            interp = result["interpretations"]
            print(f"   –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å: {interp['readability']}")
            print(f"   –°—Ç–æ–ø-—Å–ª–æ–≤–∞: {interp['stopwords']}")
            print(f"   –ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ: {interp['adjectives']}")
            print(f"   –ù–∞—Ä–µ—á–∏—è: {interp['adverbs']}")
            print(f"   –ü–æ–≤—Ç–æ—Ä–µ–Ω–∏—è: {interp['repetitions']}")
        
        print("="*80 + "\n")
    
    def analyze_batch(self, texts: List[str]) -> List[Dict]:
        """
        –ê–Ω–∞–ª–∏–∑ —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        """
        results = []
        for i, text in enumerate(texts, 1):
            print(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ–∫—Å—Ç {i}/{len(texts)}...")
            result = self.analyze_text(text, detailed=True)
            results.append(result)
        
        return results
    
    def analyze_csv(self, csv_path: str, text_column: str = "text", 
                    output_path: str = None) -> pd.DataFrame:
        """
        –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ CSV —Ñ–∞–π–ª–∞
        
        Args:
            csv_path: –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É
            text_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å —Ç–µ–∫—Å—Ç–æ–º
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ {csv_path}...")
        df = pd.read_csv(csv_path)
        
        if text_column not in df.columns:
            raise ValueError(f"–ö–æ–ª–æ–Ω–∫–∞ '{text_column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ CSV —Ñ–∞–π–ª–µ!")
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(df)} —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ç–µ–∫—Å—Ç
        results = []
        for idx, text in enumerate(df[text_column], 1):
            if idx % 10 == 0:
                print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx}/{len(df)}...")
            
            result = self.predict(text, return_proba=True)
            results.append(result)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ DataFrame
        df["is_water"] = [r["is_water"] for r in results]
        df["water_label"] = [r["water_label"] for r in results]
        df["confidence"] = [r["confidence"] for r in results]
        df["water_probability"] = [r["probabilities"]["water"] for r in results]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        for feature in self.feature_names:
            df[feature] = [r["features"][feature] for r in results]
        
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(df)}")
        print(f"   –í–æ–¥–∞: {df['is_water'].sum()} ({df['is_water'].sum()/len(df)*100:.1f}%)")
        print(f"   –ù–µ –≤–æ–¥–∞: {(~df['is_water']).sum()} ({(~df['is_water']).sum()/len(df)*100:.1f}%)")
        
        if output_path:
            df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
        
        return df


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –î–µ—Ç–µ–∫—Ç–æ—Ä '–≤–æ–¥—ã' –≤ —Ç–µ–∫—Å—Ç–∞—Ö")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
    detector = WaterDetector()
    
    print("\nüí¨ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º:")
    print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:")
    print("  - –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    print("  - 'file <–ø—É—Ç—å>' - –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞")
    print("  - 'csv <–ø—É—Ç—å>' - –∞–Ω–∞–ª–∏–∑ CSV —Ñ–∞–π–ª–∞")
    print("  - 'example' - –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏–º–µ—Ä–æ–≤")
    print("  - 'exit' - –≤—ã—Ö–æ–¥")
    
    while True:
        user_input = input("\n>>> ").strip()
        
        if user_input.lower() in ['exit', 'quit', '–≤—ã—Ö–æ–¥']:
            break
        
        elif user_input.lower().startswith('file '):
            file_path = user_input[5:].strip()
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
                result = detector.analyze_text(text, detailed=True)
                detector.print_analysis(result)
            except FileNotFoundError:
                print(f"‚ùå –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        
        elif user_input.lower().startswith('csv '):
            csv_path = user_input[4:].strip()
            try:
                df = detector.analyze_csv(csv_path, output_path=csv_path.replace('.csv', '_analyzed.csv'))
                print(f"\nüìã –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
                print(df[['water_label', 'confidence', 'water_probability']].head())
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        
        elif user_input.lower() == 'example':
            examples = [
                "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ 25% –ø—Ä–∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏–∏ –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã.",
                "–≠—Ç–æ –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ–µ –∏ –ø–æ—Ç—Ä—è—Å–∞—é—â–µ –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–æ –ø–æ–º–æ–≥–∞–µ—Ç –¥–æ—Å—Ç–∏–≥–∞—Ç—å –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ü–µ–ª–µ–π –∏ —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å –ø–ª–∞–Ω—ã."
            ]
            
            for i, example in enumerate(examples, 1):
                print(f"\n{'='*80}")
                print(f"–ü–†–ò–ú–ï–† {i}:")
                result = detector.analyze_text(example, detailed=True)
                detector.print_analysis(result)
        
        elif user_input:
            result = detector.analyze_text(user_input, detailed=True)
            detector.print_analysis(result)
    
    print("\nüëã –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")


if __name__ == "__main__":
    main()
